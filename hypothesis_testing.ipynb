{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your work for this exercise in a jupyter notebook named hypothesis_testing.ipynb.\n",
    "\n",
    "For each of the following questions, formulate a null and alternative hypothesis (be as specific as you can be), then give an example of what a true positive, true negative, type I and type II errors would look like.\n",
    "\n",
    "Is the website redesign any good?\n",
    "\n",
    "- $H_0$: Web traffic after the redesign did not increase.\n",
    "    \n",
    "- $H_a$: Web traffic after the redesign increased.\n",
    "\n",
    "- Type I error: We conclude that the redesign increased web traffic, when in reality our sample just had abnormally high traffic.\n",
    "\n",
    "- Type II error: We conclude that the redesign did not increase web traffic, but actually, our sample just had abnormally low traffic. \n",
    "\n",
    "Is our television ad driving more sales?\n",
    "\n",
    "- $H_0$: Sales did not increase after the ad aired.\n",
    "    \n",
    "- $H_a$: Sales increased after the ad aired.\n",
    "\n",
    "- Type I error: We conclude that sales increased after the ad aired, when our sample just happened to have abnormally high sales, unimpacted by the ad.\n",
    "\n",
    "- Type II error: We conclude that sales did not increase after the ad aired, when our sample actually just had abnormally low sales, despite the ad's impact.\n",
    "\n",
    "Has the network latency gone up since we switched internet service providers?\n",
    "\n",
    "- $H_0$: Since we changed ISPs, network latency has not gone up.\n",
    "    \n",
    "- $H_a$: Since we changed ISPs, network latency has gone up.\n",
    "\n",
    "- Type I error: We find that our ISP switch increased network latency, but our sample actually just had abnormally high network latency, despite the switch's negligible impact.\n",
    "\n",
    "- Type II error: We find that our ISP switch did not increase network latency, but our sample actually just had abnormally low network latency despite the significant impact of the ISP switch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.361938906974643, pvalue=0.020385578775708034)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "sample_1 = stats.norm(90, 15).rvs(40)\n",
    "sample_2 = stats.norm(100, 20).rvs(50)\n",
    "\n",
    "stats.ttest_ind(sample_1,sample_2)\n",
    "\n",
    "# Average time is different, p-value of 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.21276595744681\n",
      "20.14957264957265\n",
      "Ttest_indResult(statistic=5.260311926248542, pvalue=2.8684546158129373e-07)\n",
      "22.227272727272727\n",
      "19.130573248407643\n",
      "Ttest_indResult(statistic=4.593437735750014, pvalue=7.154374401145683e-06)\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = data('mpg')\n",
    "mpg['mpg'] = (mpg['cty'] + mpg['hwy']) / 2\n",
    "\n",
    "mpg_08 = mpg[mpg['year'] == 2008]['mpg']\n",
    "mpg_99 = mpg[mpg['year'] == 1999]['mpg']\n",
    "\n",
    "stats.ttest_ind(mpg_08, mpg_99)\n",
    "\n",
    "# No difference, p-value of 0.83\n",
    "\n",
    "compact = mpg[mpg['class'] == 'compact']['mpg']\n",
    "average_car = mpg['mpg']\n",
    "\n",
    "print(compact.mean())\n",
    "print(average_car.mean())\n",
    "print(stats.ttest_ind(compact, average_car))\n",
    "\n",
    "# Yes, compact cars get better mileage, p-value of .00000029\n",
    "\n",
    "mpg['is_auto'] = mpg['trans'].apply(lambda x: 'auto' in x)\n",
    "manual = mpg[~mpg['is_auto']]['mpg']\n",
    "auto = mpg[mpg['is_auto']]['mpg']\n",
    "\n",
    "\n",
    "print(manual.mean())\n",
    "print(auto.mean())\n",
    "print(stats.ttest_ind(manual,auto))\n",
    "\n",
    "# Yes, manual cars get better mileage, p-value of .0000071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import user, host, password\n",
    "import pandas as pd\n",
    "\n",
    "def get_db_url(username, hostname, password, db_name):\n",
    "    return f'mysql+pymysql://{username}:{password}@{hostname}/{db_name}'\n",
    "\n",
    "url = get_db_url(user, host, password, 'telco_churn')\n",
    "\n",
    "query = '''\n",
    "select tenure, monthly_charges, total_charges, phone_service, internet_service_type_id from customers;\n",
    "'''\n",
    "\n",
    "telco = pd.read_sql(query,url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3723066263198703, 5.890963580482675e-181)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24538898585362878, 7.117871077967264e-88)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isfloat(value): #credit to stackexchange user Eric Leschinski\n",
    "  try:\n",
    "    float(value)\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "\n",
    "floats_only = telco.total_charges.apply(isfloat)\n",
    "\n",
    "stats.pearsonr(telco.tenure,telco.monthly_charges) #Yes, there's a correlation. \n",
    "stats.pearsonr(telco[floats_only].tenure,telco[floats_only].total_charges.apply(float)) #Yes, there's a correlation.\n",
    "\n",
    "has_internet = telco.internet_service_type_id < 3\n",
    "has_phone = telco.phone_service == \"Yes\"\n",
    "\n",
    "stats.pearsonr(telco.tenure[has_internet], telco.monthly_charges[has_internet]) #Yes, correlated\n",
    "stats.pearsonr(telco.tenure[has_phone], telco.monthly_charges[has_phone]) #Yes, correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_db_url(user, host, password, 'employees')\n",
    "query = '''\n",
    "select datediff(curdate(),e.hire_date) as tenure,\n",
    "    salary\n",
    "    from employees as e\n",
    "    join salaries as s \n",
    "    using(emp_no)\n",
    "    where s.to_date like \"9999%%\";\n",
    "     '''\n",
    "salary_by_tenure = pd.read_sql(query,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30646256131860783, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_by_tenure['tenure'] = salary_by_tenure['tenure'] - salary_by_tenure['tenure'].min()\n",
    "\n",
    "stats.pearsonr(salary_by_tenure['tenure'],salary_by_tenure['salary']) #Yes, they're correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select datediff(curdate(),e.hire_date) as tenure,\n",
    "    count(title) as titles\n",
    "    from employees as e\n",
    "    join titles as t \n",
    "    using(emp_no)\n",
    "    group by emp_no;\n",
    "    '''\n",
    "titles_by_tenure = pd.read_sql(query,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26659892991366196, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_by_tenure['tenure'] = titles_by_tenure['tenure'] - titles_by_tenure['tenure'].min()\n",
    "\n",
    "stats.pearsonr(titles_by_tenure['tenure'],titles_by_tenure['titles']) # Yes, they're correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep = data('sleepstudy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5352302262650253, 9.894096322214812e-15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(sleep.Reaction,sleep.Days) # Yes, they're correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['Macbook', 'Not Macbook']\n",
    "columns = ['Codeup', 'Not Codeup']\n",
    "macbooks = pd.DataFrame([[49,20], [1, 30]], index=index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36.65264142122487, 1.4116760526193828e-09, 1, array([[34.5, 34.5],\n",
       "        [15.5, 15.5]]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(macbooks) #Not independent, very low p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246.91908570197074,\n",
       " 7.163203875453598e-10,\n",
       " 126,\n",
       " array([[ 0.38461538,  0.40598291,  0.79059829,  0.53418803,  0.19230769,\n",
       "          0.2991453 ,  0.17094017,  0.08547009,  0.06410256,  0.08547009,\n",
       "          0.27777778,  0.10683761,  0.2991453 ,  0.72649573,  0.57692308],\n",
       "        [ 0.15384615,  0.16239316,  0.31623932,  0.21367521,  0.07692308,\n",
       "          0.11965812,  0.06837607,  0.03418803,  0.02564103,  0.03418803,\n",
       "          0.11111111,  0.04273504,  0.11965812,  0.29059829,  0.23076923],\n",
       "        [ 6.38461538,  6.73931624, 13.12393162,  8.86752137,  3.19230769,\n",
       "          4.96581197,  2.83760684,  1.41880342,  1.06410256,  1.41880342,\n",
       "          4.61111111,  1.77350427,  4.96581197, 12.05982906,  9.57692308],\n",
       "        [ 3.        ,  3.16666667,  6.16666667,  4.16666667,  1.5       ,\n",
       "          2.33333333,  1.33333333,  0.66666667,  0.5       ,  0.66666667,\n",
       "          2.16666667,  0.83333333,  2.33333333,  5.66666667,  4.5       ],\n",
       "        [ 0.46153846,  0.48717949,  0.94871795,  0.64102564,  0.23076923,\n",
       "          0.35897436,  0.20512821,  0.1025641 ,  0.07692308,  0.1025641 ,\n",
       "          0.33333333,  0.12820513,  0.35897436,  0.87179487,  0.69230769],\n",
       "        [ 0.23076923,  0.24358974,  0.47435897,  0.32051282,  0.11538462,\n",
       "          0.17948718,  0.1025641 ,  0.05128205,  0.03846154,  0.05128205,\n",
       "          0.16666667,  0.06410256,  0.17948718,  0.43589744,  0.34615385],\n",
       "        [ 0.23076923,  0.24358974,  0.47435897,  0.32051282,  0.11538462,\n",
       "          0.17948718,  0.1025641 ,  0.05128205,  0.03846154,  0.05128205,\n",
       "          0.16666667,  0.06410256,  0.17948718,  0.43589744,  0.34615385],\n",
       "        [ 1.23076923,  1.2991453 ,  2.52991453,  1.70940171,  0.61538462,\n",
       "          0.95726496,  0.54700855,  0.27350427,  0.20512821,  0.27350427,\n",
       "          0.88888889,  0.34188034,  0.95726496,  2.32478632,  1.84615385],\n",
       "        [ 4.46153846,  4.70940171,  9.17094017,  6.1965812 ,  2.23076923,\n",
       "          3.47008547,  1.98290598,  0.99145299,  0.74358974,  0.99145299,\n",
       "          3.22222222,  1.23931624,  3.47008547,  8.42735043,  6.69230769],\n",
       "        [ 1.46153846,  1.54273504,  3.0042735 ,  2.02991453,  0.73076923,\n",
       "          1.13675214,  0.64957265,  0.32478632,  0.24358974,  0.32478632,\n",
       "          1.05555556,  0.40598291,  1.13675214,  2.76068376,  2.19230769]]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.chi2_contingency(pd.crosstab(mpg.trans, mpg.manufacturer))\n",
    "# Null: All manufacturers are equally likely to make each transmission type.\n",
    "# Alt: All manufacturers are not equally likely to make each transmission type.\n",
    "# p-value < 0.05, we reject the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/pymysql/cursors.py:170: Warning: (1292, \"Incorrect date value: '9999%' for column 'to_date' at row 1\")\n",
      "  result = self._query(query)\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select gender, dept_name\n",
    "    from employees\n",
    "    join dept_emp as de using(emp_no)\n",
    "    join departments using(dept_no)\n",
    "    where de.to_date like \"9999%%\";\n",
    "    '''\n",
    "\n",
    "gender_vs_dept = pd.read_sql(query,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3240332004060638,\n",
       " 0.5691938610810126,\n",
       " 1,\n",
       " array([[ 5893.2426013, 14969.7573987],\n",
       "        [ 8948.7573987, 22731.2426013]]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_filter = gender_vs_dept['dept_name'].apply(lambda x: x in ['Marketing', 'Sales'])\n",
    "relevant = gender_vs_dept[dept_filter]\n",
    "stats.chi2_contingency(pd.crosstab(relevant.gender, relevant.dept_name)) # No correlation, p-value is .57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "select gender, count(dm.emp_no) as m_count\n",
    "    from employees\n",
    "    left join dept_manager as dm using(emp_no)\n",
    "    group by emp_no;'''\n",
    "\n",
    "gender_vs_manager = pd.read_sql(query,url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4566857643547197,\n",
       " 0.22745818732810363,\n",
       " 1,\n",
       " array([[1.20041397e+05, 9.60331174e+00],\n",
       "        [1.79958603e+05, 1.43966883e+01]]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_vs_manager['been_manager'] = gender_vs_manager['m_count'] > 0\n",
    "\n",
    "stats.chi2_contingency(pd.crosstab(gender_vs_manager.gender, gender_vs_manager.been_manager)) # No correlation, p-value is .23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
